{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26cfb3a",
   "metadata": {},
   "source": [
    "COMPAS Data exploration and initial model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efd72757-7c21-4746-8037-2dbb3f23e425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of          id                 name      first         last  \\\n",
      "0         1     miguel hernandez     miguel    hernandez   \n",
      "1         3          kevon dixon      kevon        dixon   \n",
      "2         4             ed philo         ed        philo   \n",
      "3         5          marcu brown      marcu        brown   \n",
      "4         6   bouthy pierrelouis     bouthy  pierrelouis   \n",
      "...     ...                  ...        ...          ...   \n",
      "7209  10996        steven butler     steven       butler   \n",
      "7210  10997      malcolm simmons    malcolm      simmons   \n",
      "7211  10999      winston gregory    winston      gregory   \n",
      "7212  11000          farrah jean     farrah         jean   \n",
      "7213  11001  florencia sanmartin  florencia    sanmartin   \n",
      "\n",
      "     compas_screening_date     sex         dob  age          age_cat  \\\n",
      "0               2013-08-14    Male  1947-04-18   69  Greater than 45   \n",
      "1               2013-01-27    Male  1982-01-22   34          25 - 45   \n",
      "2               2013-04-14    Male  1991-05-14   24     Less than 25   \n",
      "3               2013-01-13    Male  1993-01-21   23     Less than 25   \n",
      "4               2013-03-26    Male  1973-01-22   43          25 - 45   \n",
      "...                    ...     ...         ...  ...              ...   \n",
      "7209            2013-11-23    Male  1992-07-17   23     Less than 25   \n",
      "7210            2014-02-01    Male  1993-03-25   23     Less than 25   \n",
      "7211            2014-01-14    Male  1958-10-01   57  Greater than 45   \n",
      "7212            2014-03-09  Female  1982-11-17   33          25 - 45   \n",
      "7213            2014-06-30  Female  1992-12-18   23     Less than 25   \n",
      "\n",
      "                  race  ...  v_decile_score  v_score_text  v_screening_date  \\\n",
      "0                Other  ...               1           Low        2013-08-14   \n",
      "1     African-American  ...               1           Low        2013-01-27   \n",
      "2     African-American  ...               3           Low        2013-04-14   \n",
      "3     African-American  ...               6        Medium        2013-01-13   \n",
      "4                Other  ...               1           Low        2013-03-26   \n",
      "...                ...  ...             ...           ...               ...   \n",
      "7209  African-American  ...               5        Medium        2013-11-23   \n",
      "7210  African-American  ...               5        Medium        2014-02-01   \n",
      "7211             Other  ...               1           Low        2014-01-14   \n",
      "7212  African-American  ...               2           Low        2014-03-09   \n",
      "7213          Hispanic  ...               4           Low        2014-06-30   \n",
      "\n",
      "      in_custody  out_custody  priors_count.1 start   end event two_year_recid  \n",
      "0     2014-07-07   2014-07-14               0     0   327     0              0  \n",
      "1     2013-01-26   2013-02-05               0     9   159     1              1  \n",
      "2     2013-06-16   2013-06-16               4     0    63     0              1  \n",
      "3            NaN          NaN               1     0  1174     0              0  \n",
      "4            NaN          NaN               2     0  1102     0              0  \n",
      "...          ...          ...             ...   ...   ...   ...            ...  \n",
      "7209  2013-11-22   2013-11-24               0     1   860     0              0  \n",
      "7210  2014-01-31   2014-02-02               0     1   790     0              0  \n",
      "7211  2014-01-13   2014-01-14               0     0   808     0              0  \n",
      "7212  2014-03-08   2014-03-09               3     0   754     0              0  \n",
      "7213  2015-03-15   2015-03-15               2     0   258     0              1  \n",
      "\n",
      "[7214 rows x 53 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"compas-scores-two-years.csv\"\n",
    "compas_data = pd.read_csv(file_path)\n",
    "\n",
    "## describing the overall dataset\n",
    "print(compas_data.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d987990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          sex  age              race  juv_fel_count  juv_misd_count  \\\n",
      "0       Male   69             Other              0               0   \n",
      "1       Male   34  African-American              0               0   \n",
      "2       Male   24  African-American              0               0   \n",
      "5       Male   44             Other              0               0   \n",
      "6       Male   41         Caucasian              0               0   \n",
      "...      ...  ...               ...            ...             ...   \n",
      "7209    Male   23  African-American              0               0   \n",
      "7210    Male   23  African-American              0               0   \n",
      "7211    Male   57             Other              0               0   \n",
      "7212  Female   33  African-American              0               0   \n",
      "7213  Female   23          Hispanic              0               0   \n",
      "\n",
      "      juv_other_count  priors_count c_charge_degree  two_year_recid  \n",
      "0                   0             0               F               0  \n",
      "1                   0             0               F               1  \n",
      "2                   1             4               F               1  \n",
      "5                   0             0               M               0  \n",
      "6                   0            14               F               1  \n",
      "...               ...           ...             ...             ...  \n",
      "7209                0             0               F               0  \n",
      "7210                0             0               F               0  \n",
      "7211                0             0               F               0  \n",
      "7212                0             3               M               0  \n",
      "7213                0             2               F               1  \n",
      "\n",
      "[6172 rows x 9 columns]>\n"
     ]
    }
   ],
   "source": [
    "## Same preprocessing as the ProPublica's analysis\n",
    "compas_data = compas_data[(compas_data.days_b_screening_arrest <= 30)\n",
    "                         & (compas_data.days_b_screening_arrest >= -30)\n",
    "                         & (compas_data.is_recid != -1)\n",
    "                         & (compas_data.c_charge_degree != 'O')\n",
    "                         & (compas_data.score_text != 'N/A')]\n",
    "\n",
    "columns_to_keep = ['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', 'two_year_recid'] \n",
    "compas_data = compas_data[columns_to_keep]\n",
    "\n",
    "print(compas_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2c3b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Age grouping to the data\n",
    "age_groups = [0, 18, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "labels = ['0-18', '19-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
    "compas_data['Age_category'] = pd.cut(compas_data['age'], bins=age_groups, labels=labels, right=False)\n",
    "compas_data = compas_data.drop(columns=['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3000aa",
   "metadata": {},
   "source": [
    "Lets see how many null values there are within the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "824d5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                0\n",
      "race               0\n",
      "juv_fel_count      0\n",
      "juv_misd_count     0\n",
      "juv_other_count    0\n",
      "priors_count       0\n",
      "c_charge_degree    0\n",
      "two_year_recid     0\n",
      "Age_category       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "compas_null_counts = compas_data.isnull().sum()\n",
    "\n",
    "print(compas_null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a34d534",
   "metadata": {},
   "source": [
    "Next we will explore how the target column of revicidism is distributed for different races and genders within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cd16eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_year_recid     0     1\n",
      "sex                       \n",
      "Female           762   413\n",
      "Male            2601  2396\n"
     ]
    }
   ],
   "source": [
    "gender_recidivism = compas_data.groupby('sex')['two_year_recid'].value_counts().unstack().fillna(0)\n",
    "print(gender_recidivism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737203e8",
   "metadata": {},
   "source": [
    "Seems that the within the data the amount of recidivist is almost equal to non-recidivist in male population.\n",
    "On the other hand in the Female population, the amount of recidivists is almost half of the non-recidivists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "888485eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_year_recid       0     1\n",
      "race                        \n",
      "African-American  1514  1661\n",
      "Asian               23     8\n",
      "Caucasian         1281   822\n",
      "Hispanic           320   189\n",
      "Native American      6     5\n",
      "Other              219   124\n"
     ]
    }
   ],
   "source": [
    "race_recidivism = compas_data.groupby('race')['two_year_recid'].value_counts().unstack().fillna(0)\n",
    "print(race_recidivism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ca261",
   "metadata": {},
   "source": [
    "The amount of Asians, Hispanic, Native American and other's is relatively low.\n",
    "Due to the scope of this project, all races except Caucasians and African-American's are filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31a9b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sex              race  juv_fel_count  juv_misd_count  juv_other_count  \\\n",
      "1     Male  African-American              0               0                0   \n",
      "2     Male  African-American              0               0                1   \n",
      "6     Male         Caucasian              0               0                0   \n",
      "8   Female         Caucasian              0               0                0   \n",
      "10    Male         Caucasian              0               0                0   \n",
      "\n",
      "    priors_count c_charge_degree  two_year_recid Age_category  \n",
      "1              0               F               1        31-40  \n",
      "2              4               F               1        19-30  \n",
      "6             14               F               1        41-50  \n",
      "8              0               M               0        31-40  \n",
      "10             0               F               0        19-30  \n"
     ]
    }
   ],
   "source": [
    "compas_data = compas_data[compas_data['race'].isin(['Caucasian', 'African-American'])]\n",
    "print(compas_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca990c48",
   "metadata": {},
   "source": [
    "After the data is explored and preprocessed we will create the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a08ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    }
   ],
   "source": [
    "## Importing libraries for the model creation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## splitting dataset\n",
    "def split_label(dataset, target_feature):\n",
    "    X = dataset.drop([target_feature], axis=1)\n",
    "    y = dataset[[target_feature]]\n",
    "    return X, y\n",
    "\n",
    "## Classification pipeline for RAI dashboard\n",
    "def create_classification_pipeline(X):\n",
    "    pipe_cfg = {\n",
    "        'number_columns': X.dtypes[(X.dtypes == 'int64') | (X.dtypes == 'float64')].index.values.tolist(),\n",
    "        'category_columns': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    } \n",
    "    num_pipe = Pipeline([\n",
    "        ('number_imputer', SimpleImputer(strategy='median')),\n",
    "        ('number_scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([('category_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "    ('category_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    feat_pipe = ColumnTransformer([\n",
    "        ('number_pipe', num_pipe, pipe_cfg['number_columns']),\n",
    "        ('category_pipe', cat_pipe, pipe_cfg['category_columns'])\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', feat_pipe),\n",
    "                           ('model', LogisticRegression(random_state=0))])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "## Logistic regression model creation\n",
    "target_feature = 'two_year_recid'\n",
    "categorical_features = ['sex', 'race', 'Age_category', 'c_charge_degree']\n",
    "\n",
    "train_data, test_data = train_test_split(compas_data, test_size=0.25, random_state=42, stratify=compas_data['two_year_recid'])\n",
    "\n",
    "X_train, y_train = split_label(train_data, target_feature)\n",
    "X_test, y_test = split_label(test_data, target_feature)\n",
    "\n",
    "pipeline = create_classification_pipeline(X_train)\n",
    "\n",
    "y_train = y_train[target_feature].to_numpy()\n",
    "y_test = y_test[target_feature].to_numpy()\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665849e",
   "metadata": {},
   "source": [
    "Initialize the Microsoft Responsible AI dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "146d29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Causal Effects\n",
      "Current Status: Generating Causal Effects.\n",
      "Current Status: Finished generating causal effects.\n",
      "Time taken: 0.0 min 4.509999416768551e-05 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Counterfactual\n",
      "Time taken: 0.0 min 1.309998333454132e-05 sec\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in double_scalars\n",
      "divide by zero encountered in log2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "divide by zero encountered in log\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Error Analysis\n",
      "Current Status: Generating error analysis reports.\n",
      "Current Status: Finished generating error analysis reports.\n",
      "Time taken: 0.0 min 0.13721399998757988 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Explanations\n",
      "Current Status: Explaining 8 features\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 70\n",
      "[LightGBM] [Info] Number of data points in the train set: 3958, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.085706\n",
      "Current Status: Explained 8 features.\n",
      "Time taken: 0.0 min 0.42172509990632534 sec\n",
      "================================================================================\n",
      "ResponsibleAI started at http://localhost:8709\n"
     ]
    }
   ],
   "source": [
    "#Import libraries for the RAI dashboard\n",
    "from responsibleai import RAIInsights\n",
    "from raiwidgets import ResponsibleAIDashboard\n",
    "from responsibleai.feature_metadata import FeatureMetadata\n",
    "from raiutils.cohort import Cohort, CohortFilter, CohortFilterMethods\n",
    "\n",
    "feature_metadata = FeatureMetadata(categorical_features=categorical_features, dropped_features=[])\n",
    "\n",
    "rai_insights = RAIInsights(model, train_data, test_data, target_feature, 'classification',\n",
    "                           feature_metadata=feature_metadata)\n",
    "\n",
    "rai_insights.explainer.add()\n",
    "rai_insights.error_analysis.add()\n",
    "rai_insights.compute()\n",
    "\n",
    "## Cohorts for filtering different ethnicities and genders\n",
    "cohort_caucasians = Cohort(\"Caucasian\")\n",
    "cohort_caucasians.add_cohort_filter(CohortFilter(method=CohortFilterMethods.METHOD_INCLUDES, arg=[\"Caucasian\"], column='race'))\n",
    "\n",
    "cohort_african_american = Cohort(\"African-American\")\n",
    "cohort_african_american.add_cohort_filter(CohortFilter(method=CohortFilterMethods.METHOD_INCLUDES, arg=[\"African-American\"], column='race'))\n",
    "\n",
    "cohort_male = Cohort(\"Male\")\n",
    "cohort_male.add_cohort_filter(CohortFilter(method=CohortFilterMethods.METHOD_INCLUDES, arg=[\"Male\"], column='sex'))\n",
    "\n",
    "cohort_female= Cohort(\"Female\")\n",
    "cohort_female.add_cohort_filter(CohortFilter(method=CohortFilterMethods.METHOD_INCLUDES, arg=[\"Female\"], column='sex'))\n",
    "\n",
    "cohort_list = [cohort_caucasians, cohort_african_american, cohort_female, cohort_male]\n",
    "\n",
    "#RAI dashboard will be hosted locally\n",
    "rai_dashboard = ResponsibleAIDashboard(rai_insights, cohort_list=cohort_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaddb32",
   "metadata": {},
   "source": [
    "The metrics can be found in the dashboard section: Model overview by inserting features sex or race to the filter.\n",
    "\n",
    "Race metrics:\n",
    "\n",
    "![alt text](Base_model_race.png)\n",
    "\n",
    "Confusion matrices:\n",
    "\n",
    "Caucasians:\n",
    "\n",
    "![alt text](Base_model_cauc.png)\n",
    "\n",
    "African Americans:\n",
    "\n",
    "![alt text](Base_model_african.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39ee545",
   "metadata": {},
   "source": [
    "Sex metrics\n",
    "\n",
    "![alt text](Base_model_sex.png)\n",
    "\n",
    "Males:\n",
    "\n",
    "![alt text](Base_model_male.png)\n",
    "\n",
    "Females:\n",
    "\n",
    "![alt text](Base_model_female.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78546a75",
   "metadata": {},
   "source": [
    "Based on the information provided, it seems that model does not satisfy equalized odds for neither both races or genders.\n",
    "\n",
    "True positive and False positive rates does not match across different groups. So the model is not fair for different ethnicities or genders.\n",
    "\n",
    "For bias mitigation we will use preprocessing method reweighin on the race and gender columns separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc53f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reweighing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_data, test_data = train_test_split(compas_data, test_size=0.25, random_state=42, stratify=compas_data['two_year_recid'])\n",
    "feature_columns = train_data.columns[:-1] \n",
    "\n",
    "## For the reweighing algorithm the data must be in binary format\n",
    "sex_encoder = LabelEncoder()\n",
    "c_charge_degree_encoder = LabelEncoder()\n",
    "age_category_encoder = LabelEncoder()\n",
    "\n",
    "train_data['sex'] = train_data['sex'].apply(lambda x:1 if x == 'Female' else 0)\n",
    "train_data['race'] = train_data['race'].apply(lambda x:1 if x == 'Caucasian' else 0)\n",
    "train_data['c_charge_degree'] = train_data['c_charge_degree'].apply(lambda x:1 if x == 'F' else 0)\n",
    "train_data['Age_category'] = age_category_encoder.fit_transform(train_data['Age_category'])\n",
    "\n",
    "privileged_groups = [{'race': 1}]  # Caucasians\n",
    "unprivileged_groups = [{'race': 0}]  # African Americans\n",
    "\n",
    "dataset = BinaryLabelDataset(\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1,\n",
    "    df=train_data,\n",
    "    label_names=['two_year_recid'],\n",
    "    protected_attribute_names=['race'],\n",
    "    unprivileged_protected_attributes=[0]\n",
    ")\n",
    "\n",
    "reweighing = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "compas_data_reweight = reweighing.fit_transform(dataset)\n",
    "\n",
    "train_data = pd.DataFrame(data=compas_data_reweight.features, columns=dataset.feature_names)\n",
    "train_data['two_year_recid'] = compas_data_reweight.labels.ravel()\n",
    "\n",
    "\n",
    "#After reweighing we will transform the data back from binary\n",
    "train_data['sex'] = train_data['sex'].map({0.0: 'Male', 1.0: 'Female'})\n",
    "train_data['race'] = train_data['race'].map({1: 'Caucasian', 0: 'African-American'})\n",
    "train_data['c_charge_degree'] = train_data['c_charge_degree'].map({1.0: 'F', 0.0: 'M'})\n",
    "train_data['Age_category'] = age_category_encoder.inverse_transform(train_data['Age_category'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f48010fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Causal Effects\n",
      "Current Status: Generating Causal Effects.\n",
      "Current Status: Finished generating causal effects.\n",
      "Time taken: 0.0 min 0.00020659994333982468 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Counterfactual\n",
      "Time taken: 0.0 min 9.599956683814526e-06 sec\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Error Analysis\n",
      "Current Status: Generating error analysis reports.\n",
      "Current Status: Finished generating error analysis reports.\n",
      "Time taken: 0.0 min 0.1088529999833554 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Explanations\n",
      "Current Status: Explaining 8 features\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 70\n",
      "[LightGBM] [Info] Number of data points in the train set: 3958, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.097719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Explained 8 features.\n",
      "Time taken: 0.0 min 0.3607378000160679 sec\n",
      "================================================================================\n",
      "ResponsibleAI started at http://localhost:8710\n"
     ]
    }
   ],
   "source": [
    "## retrain a model with reweighted data\n",
    "X_train, y_train = split_label(train_data, target_feature)\n",
    "X_test, y_test = split_label(test_data, target_feature)\n",
    "\n",
    "pipeline = create_classification_pipeline(X_train)\n",
    "\n",
    "y_train = y_train[target_feature].to_numpy()\n",
    "y_test = y_test[target_feature].to_numpy()\n",
    "\n",
    "model = pipeline.fit(X_train, y_train, model__sample_weight=compas_data_reweight.instance_weights)\n",
    "\n",
    "### RAI dashboard\n",
    "feature_metadata = FeatureMetadata(categorical_features=categorical_features, dropped_features=[])\n",
    "\n",
    "rai_insights = RAIInsights(model, train_data, test_data, target_feature, 'classification',\n",
    "                           feature_metadata=feature_metadata)\n",
    "\n",
    "rai_insights.explainer.add()\n",
    "rai_insights.error_analysis.add()\n",
    "rai_insights.compute()\n",
    "\n",
    "rai_dashboard = ResponsibleAIDashboard(rai_insights, cohort_list=cohort_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ba54f",
   "metadata": {},
   "source": [
    "The metrics after reweighing for different races\n",
    "\n",
    "![alt text](Reweigh_race.png)\n",
    "\n",
    "\n",
    "Confusion matrices:\n",
    "\n",
    "African Americans:\n",
    "\n",
    "![alt text](Reweigh_afr.png)\n",
    "\n",
    "Caucasians:\n",
    "\n",
    "![alt text](Reweigh_cau.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9c6fda",
   "metadata": {},
   "source": [
    "Then let's do the same with different genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "892bb9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Causal Effects\n",
      "Current Status: Generating Causal Effects.\n",
      "Current Status: Finished generating causal effects.\n",
      "Time taken: 0.0 min 0.00022499996703118086 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Counterfactual\n",
      "Time taken: 0.0 min 1.0299962013959885e-05 sec\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Error Analysis\n",
      "Current Status: Generating error analysis reports.\n",
      "Current Status: Finished generating error analysis reports.\n",
      "Time taken: 0.0 min 0.11126209993381053 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Explanations\n",
      "Current Status: Explaining 8 features\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 70\n",
      "[LightGBM] [Info] Number of data points in the train set: 3958, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -0.099494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Explained 8 features.\n",
      "Time taken: 0.0 min 0.36919330002274364 sec\n",
      "================================================================================\n",
      "ResponsibleAI started at http://localhost:8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<raiwidgets.responsibleai_dashboard.ResponsibleAIDashboard at 0x219f20cb010>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(compas_data, test_size=0.25, random_state=42, stratify=compas_data['two_year_recid'])\n",
    "feature_columns = train_data.columns[:-1]\n",
    "\n",
    "train_data['sex'] = train_data['sex'].apply(lambda x:1 if x == 'Female' else 0)\n",
    "train_data['race'] = train_data['race'].apply(lambda x:1 if x == 'Caucasian' else 0)\n",
    "train_data['c_charge_degree'] = train_data['c_charge_degree'].apply(lambda x:1 if x == 'F' else 0)\n",
    "train_data['Age_category'] = age_category_encoder.fit_transform(train_data['Age_category'])\n",
    "\n",
    "privileged_groups = [{'sex': 1}]  # Female\n",
    "unprivileged_groups = [{'sex': 0}]  # Males\n",
    "\n",
    "dataset = BinaryLabelDataset(\n",
    "    favorable_label=0,\n",
    "    unfavorable_label=1,\n",
    "    df=train_data,\n",
    "    label_names=['two_year_recid'],\n",
    "    protected_attribute_names=['sex'],\n",
    "    unprivileged_protected_attributes=[0]\n",
    ")\n",
    "\n",
    "reweighing = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "compas_data_reweight = reweighing.fit_transform(dataset)\n",
    "\n",
    "train_data = pd.DataFrame(data=compas_data_reweight.features, columns=dataset.feature_names)\n",
    "train_data['two_year_recid'] = compas_data_reweight.labels.ravel()\n",
    "\n",
    "train_data['sex'] = train_data['sex'].map({0.0: 'Male', 1.0: 'Female'})\n",
    "train_data['race'] = train_data['race'].map({1: 'Caucasian', 0: 'African-American'})\n",
    "train_data['c_charge_degree'] = train_data['c_charge_degree'].map({1.0: 'F', 0.0: 'M'})\n",
    "train_data['Age_category'] = age_category_encoder.inverse_transform(train_data['Age_category'].astype(int))\n",
    "\n",
    "X_train, y_train = split_label(train_data, target_feature)\n",
    "X_test, y_test = split_label(test_data, target_feature)\n",
    "pipeline = create_classification_pipeline(X_train)\n",
    "\n",
    "y_train = y_train[target_feature].to_numpy()\n",
    "y_test = y_test[target_feature].to_numpy()\n",
    "\n",
    "model = pipeline.fit(X_train, y_train, model__sample_weight=compas_data_reweight.instance_weights)\n",
    "\n",
    "##RAI dashboard\n",
    "feature_metadata = FeatureMetadata(categorical_features=categorical_features, dropped_features=[])\n",
    "\n",
    "rai_insights = RAIInsights(model, train_data, test_data, target_feature, 'classification',\n",
    "                           feature_metadata=feature_metadata)\n",
    "\n",
    "rai_insights.explainer.add()\n",
    "rai_insights.error_analysis.add()\n",
    "\n",
    "rai_insights.compute()\n",
    "\n",
    "ResponsibleAIDashboard(rai_insights, cohort_list=cohort_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a09706",
   "metadata": {},
   "source": [
    "Results for genders after reweighing\n",
    "\n",
    "Sex metrics\n",
    "\n",
    "![alt text](Reweigh_sex.png)\n",
    "\n",
    "Males:\n",
    "\n",
    "![alt text](Reweigh_male.png)\n",
    "\n",
    "Females:\n",
    "\n",
    "![alt text](Reweigh_female.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
